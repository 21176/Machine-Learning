{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BL.EN.U4CSE21176 ; S NAVIN SUNDER ; CSE - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.stats import chi2_contingency\n",
    "from itertools import product   #used to iterate over the dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB  #gaussianNB uses numeric input. Ordinal encoding is used in this case to get numeric input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. For the data provided below, calculate the prior probability for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior probability = probability of an event before it is collected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities:\n",
      "P(no) = 0.4286\n",
      "P(yes) = 0.5714\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "    {'age': '<=30', 'income': 'high', 'student': 'no', 'credit_rating': 'fair', 'buys_computer': 'no'},\n",
    "    {'age': '<=30', 'income': 'high', 'student': 'no', 'credit_rating': 'excellent', 'buys_computer': 'no'},\n",
    "    {'age': '31..40', 'income': 'high', 'student': 'no', 'credit_rating': 'fair', 'buys_computer': 'yes'},\n",
    "    {'age': '>40', 'income': 'medium', 'student': 'no', 'credit_rating': 'fair', 'buys_computer': 'yes'},\n",
    "    {'age': '>40', 'income': 'low', 'student': 'yes', 'credit_rating': 'fair', 'buys_computer': 'yes'},\n",
    "    {'age': '>40', 'income': 'low', 'student': 'yes', 'credit_rating': 'excellent', 'buys_computer': 'no'},\n",
    "    {'age': '31..40', 'income': 'low', 'student': 'yes', 'credit_rating': 'excellent', 'buys_computer': 'yes'},\n",
    "    {'age': '<=30', 'income': 'medium', 'student': 'no', 'credit_rating': 'fair', 'buys_computer': 'no'},\n",
    "    {'age': '<=30', 'income': 'low', 'student': 'yes', 'credit_rating': 'fair', 'buys_computer': 'yes'},\n",
    "    {'age': '>40', 'income': 'medium', 'student': 'yes', 'credit_rating': 'fair', 'buys_computer': 'yes'},\n",
    "    {'age': '<=30', 'income': 'medium', 'student': 'yes', 'credit_rating': 'excellent', 'buys_computer': 'yes'},\n",
    "    {'age': '31..40', 'income': 'high', 'student': 'no', 'credit_rating': 'excellent', 'buys_computer': 'yes'},\n",
    "    {'age': '31..40', 'income': 'medium', 'student': 'yes', 'credit_rating': 'fair', 'buys_computer': 'no'},\n",
    "    {'age': '>40', 'income': 'high', 'student': 'no', 'credit_rating': 'excellent', 'buys_computer': 'no'}\n",
    "]\n",
    "\n",
    "# Calculate the total number of instances\n",
    "totalInstances = len(dataset)\n",
    "\n",
    "# Calculate the prior probability for each class\n",
    "classes = set(entry['buys_computer'] for entry in dataset)\n",
    "priorProbabilities = {}\n",
    "\n",
    "for class_label in classes:\n",
    "    class_count = sum(1 for entry in dataset if entry['buys_computer'] == class_label)\n",
    "    priorProbabilities[class_label] = class_count / totalInstances\n",
    "\n",
    "print(\"Prior Probabilities:\")\n",
    "for class_label, prior_probability in priorProbabilities.items():\n",
    "    print(f\"P({class_label}) = {prior_probability:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2.Calculate the class conditional densities for various features & classes. Observe if any class conditional density has zero values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Conditional Densities:\n",
      "For class no:\n",
      "P(age | no) = 14.0000\n",
      "P(income | no) = 14.0000\n",
      "P(student | no) = 14.0000\n",
      "P(credit_rating | no) = 14.0000\n",
      "For class yes:\n",
      "P(age | yes) = 14.0000\n",
      "P(income | yes) = 14.0000\n",
      "P(student | yes) = 14.0000\n",
      "P(credit_rating | yes) = 14.0000\n",
      "\n",
      "No features have zero class conditional densities.\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store class conditional densities\n",
    "class_conditional_densities = defaultdict(dict) #defaultdict is a sub-class of a dictonary class that returns a dictionary like objects\n",
    "\n",
    "# Calculate class conditional densities for each feature and class\n",
    "for feature in dataset[0].keys():  # Assuming features are in the first sublist\n",
    "    if feature != 'buys_computer':  # Exclude the class label\n",
    "        for class_label in classes:\n",
    "            # Filter instances with the given feature and class\n",
    "            feature_class_instances = [entry for entry in dataset if entry['buys_computer'] == class_label and entry[feature] == entry[feature]]\n",
    "            \n",
    "            # Calculate class conditional density\n",
    "            density = len(feature_class_instances) / priorProbabilities[class_label]\n",
    "            class_conditional_densities[class_label][feature] = density\n",
    "\n",
    "# Print the class conditional densities\n",
    "print(\"Class Conditional Densities:\")\n",
    "for class_label, densities in class_conditional_densities.items():\n",
    "    print(f\"For class {class_label}:\")\n",
    "    for feature, density in densities.items():\n",
    "        print(f\"P({feature} | {class_label}) = {density:.4f}\")\n",
    "\n",
    "# Check if any class conditional density has zero values\n",
    "zero_density_features = [(class_label, feature) for class_label, densities in class_conditional_densities.items() for feature, density in densities.items() if density == 0]\n",
    "\n",
    "if zero_density_features:\n",
    "    print(\"\\nFeatures with zero class conditional densities:\")\n",
    "    for class_label, feature in zero_density_features:\n",
    "        print(f\"For class {class_label}, feature {feature} has zero density.\")\n",
    "else:\n",
    "    print(\"\\nNo features have zero class conditional densities.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3. Test for independence between the 4 given features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared value: 0.0\n",
      "P-value: 1.0\n",
      "\n",
      "Test Result:\n",
      "Fail to reject the null hypothesis. Features are independent.\n"
     ]
    }
   ],
   "source": [
    "#chi2_contingency null hypotheses => to check the relationship between the two variables that determines if the features are independent or not \n",
    "\n",
    "# Extract features and class labels from the dataset\n",
    "features = [entry['age'] for entry in dataset]\n",
    "income = [entry['income'] for entry in dataset]\n",
    "student = [entry['student'] for entry in dataset]\n",
    "credit_rating = [entry['credit_rating'] for entry in dataset]\n",
    "buys_computer = [entry['buys_computer'] for entry in dataset]\n",
    "\n",
    "# Create a list of unique values for each feature\n",
    "unique_values = {\n",
    "    'age': set(features),\n",
    "    'income': set(income),\n",
    "    'student': set(student),\n",
    "    'credit_rating': set(credit_rating),\n",
    "    'buys_computer': set(buys_computer)\n",
    "}\n",
    "\n",
    "# Generate all possible combinations of values for the features\n",
    "combinations = list(product(unique_values['age'], unique_values['income'], unique_values['student'], unique_values['credit_rating'], unique_values['buys_computer']))\n",
    "\n",
    "# Create a contingency table with Laplace smoothing\n",
    "contingency_table = []\n",
    "epsilon = 1e-10  # small constant to avoid zero expected frequencies\n",
    "\n",
    "for age, inc, stud, credit, buys in combinations:\n",
    "    count = sum(1 for i in range(totalInstances) if features[i] == age and buys_computer[i] == buys and income[i] == inc and student[i] == stud and credit_rating[i] == credit)\n",
    "    contingency_table.append([count + epsilon])\n",
    "\n",
    "# Perform Chi-squared test for independence\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the test results\n",
    "print(f\"Chi-squared value: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "\n",
    "# Check the significance level (e.g., alpha = 0.05)\n",
    "alpha = 0.05    #alpha can be set to any value between 0 and 1\n",
    "print(\"\\nTest Result:\")\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis. Features are not independent.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. Features are independent.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A4. Build a NaÃ¯ve-Bayes (NB) classifier for the above given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# Extract the features and target variable\n",
    "features = np.array([[row['age'], row['income'], row['student'], row['credit_rating']] for row in dataset])\n",
    "target = np.array([row['buys_computer'] for row in dataset])\n",
    "\n",
    "# Convert categorical data to numerical values using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(features.shape[1]):\n",
    "    features[:, i] = label_encoder.fit_transform(features[:, i])\n",
    "\n",
    "# Convert features to numeric values\n",
    "features = features.astype(float)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Gaussian Naive Bayes classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "gnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = gnb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A5. Build a NB classifier for your own project data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.00%\n"
     ]
    }
   ],
   "source": [
    "# Read data from Excel\n",
    "data = pd.read_excel(r\"C:\\Amrita cse\\5th Semester\\Machine Learning\\Lab\\Lab 4\\embeddingsdata.xlsx\")\n",
    "\n",
    "# Separate features and target\n",
    "features = data.iloc[:, :-1]  # Features\n",
    "target = data.iloc[:, -1]      # Target data \n",
    "\n",
    "# Convert categorical data to numerical values using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in features.columns:\n",
    "    features[col] = label_encoder.fit_transform(features[col])\n",
    "\n",
    "# Convert features to numeric values\n",
    "features = features.astype(float)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Gaussian Naive Bayes classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "gnb_classifier.fit(features_train, target_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = gnb_classifier.predict(features_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = np.sum(predictions == target_test) / len(target_test)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
